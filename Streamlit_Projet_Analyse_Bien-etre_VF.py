import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# --- Configuration de la page ---
st.set_page_config(layout="wide", page_title="Analyse du World Happiness Report", page_icon="üåç",  initial_sidebar_state="expanded")


# --- Configuration des chemins de fichiers ---
FILE_PATH_WHR = "world-happiness-report.csv"
FILE_PATH_MERGE_ID = "Merge_ID_Year_Country.csv"
FILE_PATH_WHR_2020 = "WHR20_DataForFigure2.1.xlsx"
FILE_PATH_WHR_2021 = "world-happiness-report-2021.csv"
FILE_PATH_GDP = "Logged_GDP_per_Capita_2005-2023.xlsx"
FILE_PATH_LIFE = "Healthy Life Expectancy 2000-2021.csv"

WHR_2005_2020 = pd.read_csv(FILE_PATH_WHR, sep=',')
WHR_2021 = pd.read_csv(FILE_PATH_WHR_2021, sep=',')

# --- Fonction de chargement et de nettoyage des donn√©es (avec cache Streamlit) ---
@st.cache_data
def load_and_preprocess_data():
    with st.spinner('Chargement et pr√©traitement des donn√©es...'):

        # Initial Load
        df = pd.read_csv(FILE_PATH_WHR, sep=',')

        # Add 'id' column for merging
        df['year'] = df['year'].astype('str')
        df['id'] = df['year'] + "-" + df['Country name']

        # Load ID base
        ID = pd.read_csv(FILE_PATH_MERGE_ID, sep=';')

        # Merge df & ID base
        merge_df = ID.merge(df, on='id', how='outer')
        merge_df = merge_df.drop(columns=['Country name_y', 'year_y'])
        merge_df = merge_df.rename(columns={'year_x': 'year', 'Country name_x': 'Country name'})

        # Load 2020 & 2021 data
        df_2020 = pd.read_excel(FILE_PATH_WHR_2020)
        df_2020['id'] = "2020" + "-" + df_2020['Country name']
        df_2020['year'] = "2020" # Assurer le type str

        df_2021 = pd.read_csv(FILE_PATH_WHR_2021, sep=',')
        df_2021['id'] = "2021" + "-" + df_2021['Country name']
        df_2021['year'] = "2021" # Assurer le type str

        df_concat_2020_2021 = pd.concat([df_2021, df_2020], ignore_index=True)
        df_concat_2020_2021 = df_concat_2020_2021[[
            'id', 'year', 'Country name', 'Regional indicator', 'Ladder score',
            'Logged GDP per capita', 'Social support', 'Healthy life expectancy',
            'Freedom to make life choices', 'Generosity', 'Perceptions of corruption'
        ]]

        # Prepare merge_df for final merge
        merge_df_temp = merge_df.rename(columns={
            'Log GDP per capita': 'Logged GDP per capita',
            'Healthy life expectancy at birth': 'Healthy life expectancy'
        }).copy() # Utiliser .copy() pour √©viter SettingWithCopyWarning

        # Ensure 'year' is consistent type before merging
        merge_df_temp['year'] = merge_df_temp['year'].astype(str)
        df_concat_2020_2021['year'] = df_concat_2020_2021['year'].astype(str)


        df_final_merge = pd.merge(merge_df_temp, df_concat_2020_2021, on=['id', 'year', 'Country name'], how='outer', suffixes=('_x', '_y'))

        # Fill NaN from new data
        for col_name in ['Logged GDP per capita', 'Social support', 'Healthy life expectancy',
                         'Freedom to make life choices', 'Generosity', 'Perceptions of corruption']:
            df_final_merge[col_name] = df_final_merge[f'{col_name}_x'].fillna(df_final_merge[f'{col_name}_y'])
        df_final_merge['Life Ladder'] = df_final_merge['Life Ladder'].fillna(df_final_merge['Ladder score'])

        # Drop duplicate columns
        df_final_merge = df_final_merge.drop(columns=[col for col in df_final_merge.columns if '_x' in col or '_y' in col or col == 'Ladder score'])

        # Reorder columns (d√©finir reorder ici car c'est n√©cessaire pour le traitement)
        reorder = ['id', 'year', 'Country name', 'ISO-alpha3 Code', 'Regional indicator', 'Life Ladder', 'Logged GDP per capita',
                   'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption',
                   'Positive affect', 'Negative affect']
        df_final_merge = df_final_merge[reorder]

        # Enrich Regional indicator
        df_final_merge['Regional indicator'] = df_final_merge['Regional indicator'].fillna(df_final_merge.groupby('Country name')['Regional indicator'].transform('first'))

        # Fill specific missing regions
        pays_region = {
            'Angola': 'Sub-Saharan Africa', 'Belize': 'Latin America and Caribbean', 'Bhutan': 'South Asia',
            'Cuba': 'Latin America and Caribbean', 'Djibouti': 'Sub-Saharan Africa', 'Guyana': 'Latin America and Caribbean',
            'North Macedonia': 'Central and Eastern Europe', 'Oman': 'Middle East and North Africa',
            'Qatar': 'Middle East and North Africa', 'Somalia': 'Middle East and North Africa',
            'Somaliland region': 'Middle East and North Africa', 'Sudan': 'Sub-Saharan Africa',
            'Suriname': 'Latin America and Caribbean', 'Syria': 'Middle East and North Africa'
        }
        df_final_merge['Regional indicator'] = df_final_merge['Regional indicator'].fillna(df_final_merge['Country name'].map(pays_region))

        # Enrich ISO-alpha3 Code
        df_final_merge['ISO-alpha3 Code'] = df_final_merge['ISO-alpha3 Code'].fillna(df_final_merge.groupby('Country name')['ISO-alpha3 Code'].transform('first'))
        pays_ISO = {'Macedonia': 'MKD'}
        df_final_merge['ISO-alpha3 Code'] = df_final_merge['ISO-alpha3 Code'].fillna(df_final_merge['Country name'].map(pays_ISO))

        # Convert year to string for ID
        df_final_merge['year'] = df_final_merge['year'].astype('str')
        df_final_merge['id'] = df_final_merge['year'] + "-" + df_final_merge['ISO-alpha3 Code']

        # Load and merge GDP data
        GDP = pd.read_excel(FILE_PATH_GDP)
        GDP['Time'] = GDP['Time'].astype('str')
        GDP['id'] = GDP['Time'] + "-" + GDP['Country Code']
        GDP = GDP.rename(columns={'Time': 'year_gdp', 'Country Name': 'Country name_gdp', 'Country Code': 'ISO-alpha3 Code_gdp', 'LN': 'Logged GDP per capita_new'})
        GDP_merge = GDP[['id', 'year_gdp', 'Country name_gdp', 'ISO-alpha3 Code_gdp', 'Logged GDP per capita_new']]
        df_final_merge = pd.merge(df_final_merge, GDP_merge, on='id', how='left')
        df_final_merge['Logged GDP per capita'] = df_final_merge['Logged GDP per capita'].fillna(df_final_merge['Logged GDP per capita_new'])
        df_final_merge = df_final_merge.drop(columns=['Logged GDP per capita_new', 'year_gdp', 'Country name_gdp', 'ISO-alpha3 Code_gdp'])


        # Load and merge Life Expectancy data
        Life = pd.read_csv(FILE_PATH_LIFE, sep=';')
        Life['Period'] = Life['Period'].astype('str')
        Life['id'] = Life['Period'] + "-" + Life['SpatialDimValueCode']
        Life = Life.rename(columns={'Period': 'year_life', 'Location': 'Country name_life', 'SpatialDimValueCode': 'ISO-alpha3 Code_life', 'FactValueNumeric': 'Healthy life expectancy_new'})
        Life = Life.loc[(Life['Dim1'] == 'Both sexes')]
        Life_merge = Life[['id', 'year_life', 'Country name_life', 'ISO-alpha3 Code_life', 'Healthy life expectancy_new']]
        df_final_merge = pd.merge(df_final_merge, Life_merge, on='id', how='left')
        df_final_merge['Healthy life expectancy'] = df_final_merge['Healthy life expectancy'].fillna(df_final_merge['Healthy life expectancy_new'])
        df_final_merge = df_final_merge.drop(columns=['Healthy life expectancy_new', 'year_life', 'Country name_life', 'ISO-alpha3 Code_life'])

        # Drop rows that are entirely NaN in relevant columns (result of initial merge with empty ID years)
        colonnes_a_checker = ['Life Ladder', 'Logged GDP per capita', 'Social support', 'Healthy life expectancy',
                              'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'Positive affect',
                              'Negative affect']
        df_final_merge['lignes_NaN'] = df_final_merge[colonnes_a_checker].isna().all(axis=1)
        index_to_drop = df_final_merge[df_final_merge['lignes_NaN'] == True].index
        df_final_merge = df_final_merge.drop(index_to_drop)
        df_final_merge = df_final_merge.drop(columns=['lignes_NaN'])

    return df_final_merge, df

# Charger les donn√©es (cette fonction ne s'ex√©cutera qu'une seule fois gr√¢ce √† @st.cache_data)
df_processed, df_original = load_and_preprocess_data()

# Mettre le DataFrame trait√© dans l'√©tat de session pour qu'il soit accessible par toutes les "pages"
st.session_state['df_processed'] = df_processed
st.session_state['df_original'] = df_original


# Base df avec code ID & Pays
df = pd.read_csv(FILE_PATH_WHR, sep=',')
# Add 'id' column for merging
df['year'] = df['year'].astype('str')
df['id'] = df['year'] + "-" + df['Country name']
# Load ID base
ID = pd.read_csv(FILE_PATH_MERGE_ID, sep=';')
# Merge df & ID base
merge_df_ISO = ID.merge(df, on='id', how='outer')
merge_df_ISO = merge_df_ISO.drop(columns=['Country name_y', 'year_y'])
merge_df_ISO = merge_df_ISO.rename(columns={'year_x': 'year', 'Country name_x': 'Country name'})



# --- Fonctions pour chaque "page" ---

def home_page(): 

    st.title("üåç Projet Analyse du bien-√™tre sur Terre - Data Analyse - Feb25 Continu")

    st.markdown("---")

    st.image('STREAMLIT-Couv.jpg')


    st.markdown("---")
    st.subheader(" üåü Pr√©sentation du sujet, du probl√®me et des enjeux")
    st.markdown(" ##### Dans ce projet nous allons effectuer une analyse approfondie des donn√©es collect√©es par le World Happiness Report men√© par l‚ÄôOrganisation des Nations Unies.")
    
    st.markdown("""
    
    Cette enqu√™te a pour objectif d‚Äôestimer le bonheur des pays autour de la plan√®te et de comparer la qualit√© de vie des populations par nation et par zone g√©ographique 
    en collectant de nombreuses donn√©es socio-√©conomiques. Les donn√©es sur lesquelles travaille l‚ÄôONU int√®grent diff√©rents aspects comme le PIB par habitant, le soutien social, 
    l'esp√©rance de vie d‚Äôun individu en bonne sant√© depuis sa naissance, la libert√© de faire des propres choix de vie, la g√©n√©rosit√© et la perception de la corruption, 
    mettant ainsi en lumi√®re des disparit√©s parfois significatives entre pays. 
                          
     """)
    
    st.info("######  L‚Äôobjectif de ce projet est de pr√©senter ces donn√©es √† l‚Äôaide de visualisations interactives et de d√©terminer les combinaisons de facteurs permettant " \
    "d‚Äôexpliquer pourquoi certains pays sont mieux class√©s que les autres.")
    
    st.markdown("### üéØ Nos Questions Cl√©s")  

    st.markdown("""          

    **- Quels sont les 10 pays les plus heureux ?** 
                
    **- Quels sont les 10 pays les moins heureux ?** 
                
    **- Les Etats les plus riches sont-ils consid√©r√©s comme les plus heureux ?** 
                
    **- Quels sont les facteurs les plus d√©terminants du bonheur ?**
                
    **- Existe-t-il une fracture du bonheur entre zones g√©ographiques ou entre continents ?** 
                
    **- Et surtout : comment ces facteurs interagissent-ils pour favoriser, ou au contraire freiner, le bien-√™tre global d‚Äôune population ?**       
    
    """)


    st.info("###### C‚Äôest √† travers une analyse structur√©e du bien-√™tre sur Terre que nous tenterons d'apporter des √©l√©ments de r√©ponse √† ces questions.")

    
    


def presentation_donnees():
    st.title("üåç Pr√©sentation des jeux de donn√©es du WHR")

    st.markdown("""
                
    Les fichiers ‚Äúworld-happiness-report-2021.csv‚Äù et ‚Äúworld-happiness-report.csv‚Äù regroupent les r√©sultats du rapport sur le bonheur men√© sous la direction de l‚ÄôONU. 
    
    Les principales donn√©es proviennent d‚Äôun sondage r√©alis√© par l‚Äôentreprise Gallup. "
                
    """)
    st.subheader(" Voici un aper√ßu des premi√®res lignes et des informations g√©n√©rales des dataset initiaux :")
    st.markdown("""
    
    **üåü Chaque ligne des deux jeux de donn√©es repr√©sente un pays, une ann√©e et les scores de bien-√™tre selon plusieurs crit√®res √©tablis.**
                
    """)

    st.markdown("---")
    st.subheader("1.1 WHR 2005-2020")
    st.write(f"Nombre de lignes dataframe 2005 √† 2020 : **{len(WHR_2005_2020)}**")
    st.write(f"Nombre de colonnes : **{WHR_2005_2020.shape[1]}**")
    st.write(f"Nombre total de valeurs manquantes : **{WHR_2005_2020.isna().sum().sum()}**")
    st.dataframe(WHR_2005_2020.head())

    info_2005_2020 = WHR_2005_2020.info
    st.text(info_2005_2020)
    
    info_str = ""
    with redirect_stdout(sys.stdout) as stdout:
        WHR_2005_2020.info()
        info_str = stdout.getvalue()
    st.text(info_str)

    st.dataframe(WHR_2005_2020.describe())

    st.markdown("---")
    st.subheader("1.2 WHR 2021")
    st.write(f"Nombre de lignes dataframe 2021 : **{len(WHR_2021)}**")
    st.write(f"Nombre de colonnes : **{WHR_2021.shape[1]}**")
    st.write(f"Nombre total de valeurs manquantes : **{WHR_2021.isna().sum().sum()}**")
    st.dataframe(WHR_2021.head())
    


    st.dataframe(WHR_2021.describe())

def dataviz():
    st.title("üåç Analyse des donn√©es du WHR avec figures de DataVizualization")

    st.subheader("1.1 Score du bonheur")

    st.markdown("""
    Les variables ‚ÄúLadder score‚Äù et ‚ÄúLife Ladder‚Äù correspondent √† l'indice de bonheur subjectif sur "l'√©chelle du Bonheur". 
                
    Selon l'√©tude, chaque pays a obtenu un score bas√© sur une √©chelle de 0 √† 10 (le 0 repr√©sente le score le plus bas et le 10 le meilleur).
    
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("DATA 2005-2020 : Distribution Life Ladder")
        fig, ax = plt.subplots(figsize=(3, 3))
        ax.set_ylim(0, 10)
        sns.boxplot(y= WHR_2005_2020["Life Ladder"], color="blue")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    with col2:
        st.subheader("DATA 2021 : Distribution Ladder Score")
        fig, ax = plt.subplots(figsize=(3, 3))
        ax.set_ylim(0, 10)
        sns.boxplot(y= WHR_2021["Ladder score"], color="blue")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    st.subheader("1.2 PIB par habitant")

    st.markdown("""
    Les variables ‚ÄúLogged GDP per Capita‚Äù et ‚ÄúLog GDP per Capita‚Äù repr√©sentent le PIB par habitant. Ces variables sont ‚Äúlogarithm√©es‚Äù pour att√©nuer l‚Äôimpact des valeurs extr√™mes.
    
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("DATA 2005-2020 : Distribution Log GDP per capita")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2005_2020["Log GDP per capita"], color="#C832BE")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    with col2:
        st.subheader("DATA 2021 : Distribution Logged GDP per capita")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2021["Logged GDP per capita"], color="#C832BE")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    st.subheader("1.3 Support Social")

    st.markdown("""
    La variable Social support mesure la perception des citoyens d‚Äôavoir quelqu‚Äôun sur qui compter en cas de besoin.
    
    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("DATA 2005-2020 : Distribution Social Support")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2005_2020["Social support"], color="#FF7873")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    with col2:
        st.subheader("DATA 2021 : Distribution Social Support")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2021["Social support"], color="#FF7873")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    st.subheader("1.4 Esp√©rance de vie en bonne sant√©")

    st.markdown("""
    Les variables ‚ÄúHealthy life expectancy‚Äù et ‚ÄúHealthy life expectancy at birth‚Äù repr√©sentent l‚Äôesp√©rance de vie ajust√©e sur la sant√©, 
    c‚Äôest-√†-dire le nombre moyen d‚Äôann√©es qu‚Äôun individu peut esp√©rer vivre en bonne sant√© dans chaque pays.

    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("DATA 2005-2020 : Healthy life expectancy at birth")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2005_2020["Healthy life expectancy at birth"], color="#009692")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    with col2:
        st.subheader("DATA 2021 : Healthy life expectancy")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2021["Healthy life expectancy"], color="#009692")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    st.subheader("1.5 Libert√© de faire des choix")

    st.markdown("""
    La variable ‚ÄúFreedom to make life choices‚Äù refl√®te la perception des individus quant √† leur libert√© de choisir leur mode de vie, leurs d√©cisions personnelles et leur avenir. 
    
    Elle est mesur√©e sur une √©chelle de 0 √† 1, o√π 1 repr√©sente un haut niveau de libert√© per√ßue.

    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("DATA 2005-2020 : Freedom to make life choices")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2005_2020["Freedom to make life choices"], color="#FFA100")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    with col2:
        st.subheader("DATA 2021 : Freedom to make life choices")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2021["Freedom to make life choices"], color="#FFA100")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    st.subheader("1.6 G√©n√©rosit√©")

    st.markdown("""
    La variable Generosity mesure la tendance des citoyens √† faire des dons (en argent ou en temps) √† des ≈ìuvres caritatives, rapport√©e √† leur revenu. 

    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("DATA 2005-2020 : Generosity")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2005_2020["Generosity"], color="#7DB456")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    with col2:
        st.subheader("DATA 2021 : Generosity")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2021["Generosity"], color="#7DB456")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    st.subheader("1.7 Perception de la corruption")

    st.markdown("""
    La variable Perceptions of corruption mesure le niveau de corruption per√ßue par les citoyens d‚Äôun pays dans les institutions publiques (gouvernement, entreprises). 
    
    Elle est exprim√©e sur une √©chelle de 0 √† 1 (0 = corruption per√ßue comme tr√®s forte et 1 = tr√®s faible corruption per√ßue)

    """)

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("DATA 2005-2020 : Perceptions of corruption")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2005_2020["Perceptions of corruption"], color="#C3175C")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)

    with col2:
        st.subheader("DATA 2021 : Perceptions of corruption")
        fig, ax = plt.subplots(figsize=(3, 3))
        sns.boxplot(y= WHR_2021["Perceptions of corruption"], color="#C3175C")
        ax.set_ylabel("")
        st.pyplot(fig, use_container_width=False)
  


def pre_processing():
    st.title("üåç Pr√© Processing et nettoyage des donn√©es")
    
    st.markdown(""" #####
    La base de donn√©es de 2005 √† 2020 ne comporte pas √©norm√©ment de valeurs manquantes (373 NaN). 
    
    Toutefois, en approfondissant l‚Äôanalyse, en fusionnant le dataframe avec une base continue: Id -> Ann√©e & pays de 2005 √† 2020. Ajout du code ISO alpha 3: code universel par pays.
    
    Le constat n'est plus le m√™me : il manque un grand nombre de donn√©es par ann√©e et par pays.

    """)

    st.subheader("üéØ Poursuivons notre analyse afin d'enrichir le dataset sur les valeurs manquantes, en voici les diff√©rentes √©tapes :")

    st.markdown("""
                
    - Enrichir l'ann√©e 2020 avec le rapport du WHR disponible en ligne
    - Fusion de notre 2√®me jeu de donn√©es du WHR sur l'ann√©e 2021
    - Enrichir les donn√©es de l'indicateur du PIB avec les donn√©es de la Banque Mondiale
    - Enrichir les donn√©es de l'indicateur de l'esp√©rance de vie avec les donn√©es de l'OMS.

    """)

    st.markdown("---")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.subheader("1.1 Donn√©es Originales")
        st.write(f"Nombre de lignes dataframe 2005-2020 : **{len(df_original)}**")
        st.write(f"Nombre de colonnes : **{df_original.shape[1]}**")
        st.write(f"Nombre total de valeurs manquantes originales : **{df_original.isna().sum().sum()}**")
        total_nan_original = df_original.isna().sum().sum()
        st.write(f"Pourcentage de valeurs manquantes originales : **{round((total_nan_original / (WHR_2005_2020.shape[0] * WHR_2005_2020.shape[1])) * 100, 2)}%**")
        st.dataframe(df_original.isna().sum().rename("NaN Count").reset_index().rename(columns={'index': 'Column'}))
    
    with col2:
        st.subheader("1.2 Donn√©es avec code ID & Pays")
        st.write(f"Nombre de lignes dataframe 2005-2020 : **{len(merge_df_ISO)}**")
        st.write(f"Nombre de colonnes : **{merge_df_ISO.shape[1]}**")
        st.write(f"Nombre total de valeurs manquantes originales : **{merge_df_ISO.isna().sum().sum()}**")
        total_nan_merge = merge_df_ISO.isna().sum().sum()
        st.write(f"Pourcentage de valeurs manquantes originales : **{round((total_nan_merge / (merge_df_ISO.shape[0] * merge_df_ISO.shape[1])) * 100, 2)}%**")
        st.dataframe(merge_df_ISO.isna().sum().rename("NaN Count").reset_index().rename(columns={'index': 'Column'}))

    with col3:
        st.subheader("1.3 Donn√©es Pr√©trait√©es et Enrichies")
        st.write(f"Nombre de lignes apr√®s traitement : **{df_processed.shape[0]}**")
        st.write(f"Nombre de colonnes apr√®s traitement : **{df_processed.shape[1]}**")
        total_nan_processed = df_processed.isna().sum().sum()
        st.write(f"Nombre total de valeurs manquantes apr√®s traitement : **{total_nan_processed}**")
        st.write(f"Pourcentage de valeurs manquantes apr√®s traitement : **{round((total_nan_processed / (df_processed.shape[0] * df_processed.shape[1])) * 100, 2)}%**")
        st.dataframe(df_processed.isna().sum().rename("NaN Count").reset_index().rename(columns={'index': 'Column'}))

    st.markdown("---")
    st.subheader("1.4 Aper√ßu de notre dataset final")

    st.write("Le dataset a √©t√© fusionn√© avec des donn√©es suppl√©mentaires et les valeurs manquantes ont √©t√© trait√©es. En voici les premi√®res lignes :")

    st.dataframe(df_processed.head(10))

    st.markdown("---")
    st.markdown("""
    Il nous reste encore 5149 donn√©es manquantes, soit 13% de valeurs manquantes dans notre jeu de donn√©es. 
    Nous nous rendons compte que notre analyse ne va pas √™tre si ais√©e au vu du grand nombre de donn√©es absentes.
    
    Nous avons fait le choix de ne pas d√©naturer l‚Äôanalyse du WHR et de ne pas remplacer les valeurs manquantes par des moyennes ou des donn√©es externes.
    En effet, l‚Äôanalyse du WHR est bien sp√©cifique avec des questions pos√©es sur un √©chantillon de personnes. 
                
    Nous allons donc poursuivre notre analyse avec, tout de m√™me, un grand nombre de donn√©es exploitables sur un large panel de 167 pays 
    et avec une amplitude temporelle de 17 ann√©es (2005 √† 2021).
    

    """)
    st.markdown("---")
    st.info("#### üåü Le dataset est maintenant pr√™t pour une analyse approfondie.")

def analyse_des_tendances_page():
    st.title("üåç Tendances Globales (2005-2021)")
    st.markdown("---")
    st.write("Explorons comment les indicateurs cl√©s du bonheur ont √©volu√© au fil des ans.")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.subheader("Bonheur Global (Life Ladder)")
        fig, ax = plt.subplots(figsize=(8, 4))
        sns.barplot(x='year', y='Life Ladder', data=df_processed, ax=ax, palette='viridis')
        ax.set_ylim(3, 7)
        ax.set_title("√âvolution du Life Ladder")
        ax.set_xlabel("Ann√©e")
        ax.set_ylabel("Score Life Ladder")
        ax.tick_params(axis='x', rotation=45)
        st.pyplot(fig)

    with col2:
        st.subheader("Esp√©rance de Vie en Bonne Sant√©")
        fig, ax = plt.subplots(figsize=(8, 4))
        sns.barplot(x='year', y='Healthy life expectancy', data=df_processed, ax=ax, palette='mako')
        ax.set_ylim(45, 70)
        ax.set_title("√âvolution de l'Esp√©rance de Vie")
        ax.set_xlabel("Ann√©e")
        ax.set_ylabel("Ann√©es")
        ax.tick_params(axis='x', rotation=45)
        st.pyplot(fig)

    with col3:
        st.subheader("PIB par Habitant")
        fig, ax = plt.subplots(figsize=(8, 4))
        sns.barplot(x='year', y='Logged GDP per capita', data=df_processed, ax=ax, palette='rocket')
        ax.set_ylim(7, 10)
        ax.set_title("√âvolution du Logged GDP per capita")
        ax.set_xlabel("Ann√©e")
        ax.set_ylabel("Log PIB par Habitant")
        ax.tick_params(axis='x', rotation=45)
        st.pyplot(fig)

    st.markdown("---")
    st.markdown("""
    L'ann√©e 2005 contient seulement 27 donn√©es sur les 167 pays pr√©sents, ce qui explique cet √©cart.
    
    Il faudra pousser l‚Äôanalyse en d√©tail par indicateurs afin de comprendre ces diff√©rentes √©volutions du ‚Äúlife ladder‚Äù au fil des ann√©es. 
    Ici, on repr√©sente seulement une moyenne de l‚Äôensemble des pays par ann√©e. 
    
    Attention toutefois, toutes les ann√©es ne disposent pas du m√™me nombre de pays par ann√©e.
                
    """)

    st.info("##### Les graphiques montrent une tendance g√©n√©rale √† l'am√©lioration de l'esp√©rance de vie et du PIB, tandis que le score du bonheur reste relativement stable avec des variations annuelles.")


def correlations():
    st.title("üåç Matrice de corr√©lation")
    st.markdown("---")

    st.write("##### La matrice ci-dessous montre la corr√©lation entre les diff√©rents indicateurs du World Happiness Report.")
    cor = df_processed.corr(numeric_only=True)
    fig_corr, ax_corr = plt.subplots(figsize=(10, 8))
    sns.heatmap(cor, annot=True, ax=ax_corr, cmap='coolwarm', fmt=".2f")
    ax_corr.set_title("Matrice de Corr√©lation WHR (2005-2021)")
    st.pyplot(fig_corr)

    st.markdown("""#####
    Les indicateurs comme le PIB par habitant, l‚Äôesp√©rance de vie en bonne sant√©, le support social ont l‚Äôair d‚Äô√™tre fortement corr√©l√©s au score du bonheur. 
    D‚Äôautres indicateurs comme la corruption ou la g√©n√©rosit√© ont quant √† eux, au contraire, une tr√®s faible corr√©lation. 
    Attention, toutefois il s‚Äôagit des indicateurs avec le plus de donn√©es manquantes.
    """)

    st.markdown("---")

 
    st.info("#### üåü A pr√©sent poursuivons notre analyse du bien-√™tre sur terre avec l'outil PowerBI. Nous √©tofferons notre analyse avec des indicateurs externes.")


# --- Logiciel de navigation (dans la barre lat√©rale) ---
st.sidebar.title("Analyse du bien-√™tre")
page_selection = st.sidebar.radio(
    "Choisissez une page :",
    (
        "Accueil",
        "Synth√®se jeux de donn√©es",
        "Datavisualisation",
        "Pr√© Processing des donn√©es",
        "Analyse des Tendances",
        "Matrice de corr√©lation"
    )
)

# --- Affichage de la page s√©lectionn√©e ---
if page_selection == "Accueil":
    home_page()
elif page_selection == "Synth√®se jeux de donn√©es":
    presentation_donnees()  
elif page_selection == "Datavisualisation":
    dataviz()  
elif page_selection == "Pr√© Processing des donn√©es":
    pre_processing()
elif page_selection == "Analyse des Tendances":
    analyse_des_tendances_page()
elif page_selection == "Matrice de corr√©lation":

    correlations()



